{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Eksperimen Proyek Akhir SMSML\n",
                "## Membangun Sistem Machine Learning - Dicoding Indonesia\n",
                "### Nama: Dafis Nadhif Saputra\n",
                "### Dataset: Breast Cancer Wisconsin (Diagnostic)\n",
                "\n",
                "Notebook ini melakukan eksperimen preprocessing data untuk dataset Breast Cancer Wisconsin."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Libraries imported successfully!\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Set style\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "sns.set_palette('husl')\n",
                "\n",
                "print('Libraries imported successfully!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Loading\n",
                "\n",
                "Memuat dataset Breast Cancer Wisconsin dari file CSV."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset loaded successfully!\n",
                        "Dataset shape: (569, 31)\n",
                        "\n",
                        "Columns:\n",
                        "['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension', 'target']\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>mean radius</th>\n",
                            "      <th>mean texture</th>\n",
                            "      <th>mean perimeter</th>\n",
                            "      <th>mean area</th>\n",
                            "      <th>target</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr><td>0</td><td>17.99</td><td>10.38</td><td>122.8</td><td>1001.0</td><td>0</td></tr>\n",
                            "    <tr><td>1</td><td>20.57</td><td>17.77</td><td>132.9</td><td>1326.0</td><td>0</td></tr>\n",
                            "    <tr><td>2</td><td>19.69</td><td>21.25</td><td>130.0</td><td>1203.0</td><td>0</td></tr>\n",
                            "    <tr><td>3</td><td>11.42</td><td>20.38</td><td>77.58</td><td>386.1</td><td>0</td></tr>\n",
                            "    <tr><td>4</td><td>20.29</td><td>14.34</td><td>135.1</td><td>1297.0</td><td>0</td></tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   mean radius  mean texture  mean perimeter  mean area  target\n",
                            "0        17.99         10.38           122.8     1001.0       0\n",
                            "1        20.57         17.77           132.9     1326.0       0\n",
                            "2        19.69         21.25           130.0     1203.0       0\n",
                            "3        11.42         20.38           77.58      386.1       0\n",
                            "4        20.29         14.34           135.1     1297.0       0"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Load dataset from CSV file\n",
                "df = pd.read_csv('../data/breast_cancer_data.csv')\n",
                "\n",
                "print('Dataset loaded successfully!')\n",
                "print(f'Dataset shape: {df.shape}')\n",
                "print(f'\\nColumns:')\n",
                "print(df.columns.tolist())\n",
                "\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Exploratory Data Analysis (EDA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Dataset Info ===\n",
                        "Shape: (569, 31)\n",
                        "\n",
                        "Data Types:\n",
                        "mean radius                float64\n",
                        "mean texture               float64\n",
                        "mean perimeter             float64\n",
                        "mean area                  float64\n",
                        "mean smoothness            float64\n",
                        "mean compactness           float64\n",
                        "mean concavity             float64\n",
                        "mean concave points        float64\n",
                        "mean symmetry              float64\n",
                        "mean fractal dimension     float64\n",
                        "radius error               float64\n",
                        "texture error              float64\n",
                        "perimeter error            float64\n",
                        "area error                 float64\n",
                        "smoothness error           float64\n",
                        "compactness error          float64\n",
                        "concavity error            float64\n",
                        "concave points error       float64\n",
                        "symmetry error             float64\n",
                        "fractal dimension error    float64\n",
                        "worst radius               float64\n",
                        "worst texture              float64\n",
                        "worst perimeter            float64\n",
                        "worst area                 float64\n",
                        "worst smoothness           float64\n",
                        "worst compactness          float64\n",
                        "worst concavity            float64\n",
                        "worst concave points       float64\n",
                        "worst symmetry             float64\n",
                        "worst fractal dimension    float64\n",
                        "target                       int64\n",
                        "\n",
                        "Missing Values:\n",
                        "Total missing values: 0\n",
                        "\n",
                        "Target Distribution:\n",
                        "0 (Malignant): 212 (37.26%)\n",
                        "1 (Benign): 357 (62.74%)"
                    ]
                }
            ],
            "source": [
                "print('=== Dataset Info ===')\n",
                "print(f'Shape: {df.shape}')\n",
                "print('\\nData Types:')\n",
                "print(df.dtypes)\n",
                "print('\\nMissing Values:')\n",
                "print(f'Total missing values: {df.isnull().sum().sum()}')\n",
                "print('\\nTarget Distribution:')\n",
                "target_counts = df['target'].value_counts()\n",
                "print(f'0 (Malignant): {target_counts[0]} ({target_counts[0]/len(df)*100:.2f}%)')\n",
                "print(f'1 (Benign): {target_counts[1]} ({target_counts[1]/len(df)*100:.2f}%)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "",
                        "text/plain": [
                            "<Figure size 1200x400>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Target distribution visualization\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "\n",
                "# Bar plot\n",
                "target_counts = df['target'].value_counts()\n",
                "colors = ['#ff6b6b', '#4ecdc4']\n",
                "axes[0].bar(['Malignant (0)', 'Benign (1)'], [target_counts[0], target_counts[1]], color=colors)\n",
                "axes[0].set_title('Target Distribution')\n",
                "axes[0].set_ylabel('Count')\n",
                "\n",
                "# Pie chart\n",
                "axes[1].pie([target_counts[0], target_counts[1]], labels=['Malignant', 'Benign'], \n",
                "            autopct='%1.1f%%', colors=colors, explode=[0.05, 0])\n",
                "axes[1].set_title('Target Proportion')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/eda_target_distribution.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "",
                        "text/plain": [
                            "<Figure size 1000x800>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Correlation heatmap for selected features\n",
                "selected_features = ['mean radius', 'mean texture', 'mean perimeter', 'mean area', \n",
                "                     'mean smoothness', 'mean compactness', 'mean concavity', 'target']\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(df[selected_features].corr(), annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
                "plt.title('Correlation Heatmap (Selected Features)')\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/eda_correlation.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Data Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Preprocessing Steps ===\n",
                        "\n",
                        "1. Checking for missing values...\n",
                        "   No missing values found.\n",
                        "\n",
                        "2. Separating features and target...\n",
                        "   Features shape: (569, 30)\n",
                        "   Target shape: (569,)\n",
                        "\n",
                        "3. Train-test split (80-20)...\n",
                        "   Training samples: 455\n",
                        "   Testing samples: 114\n",
                        "\n",
                        "4. Feature scaling with StandardScaler...\n",
                        "   Scaling complete!"
                    ]
                }
            ],
            "source": [
                "print('=== Preprocessing Steps ===')\n",
                "\n",
                "# 1. Check for missing values\n",
                "print('\\n1. Checking for missing values...')\n",
                "if df.isnull().sum().sum() == 0:\n",
                "    print('   No missing values found.')\n",
                "else:\n",
                "    print('   Handling missing values...')\n",
                "    df = df.fillna(df.median())\n",
                "\n",
                "# 2. Separate features and target\n",
                "print('\\n2. Separating features and target...')\n",
                "X = df.drop('target', axis=1)\n",
                "y = df['target']\n",
                "print(f'   Features shape: {X.shape}')\n",
                "print(f'   Target shape: {y.shape}')\n",
                "\n",
                "# 3. Train-test split\n",
                "print('\\n3. Train-test split (80-20)...')\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "print(f'   Training samples: {len(X_train)}')\n",
                "print(f'   Testing samples: {len(X_test)}')\n",
                "\n",
                "# 4. Feature scaling\n",
                "print('\\n4. Feature scaling with StandardScaler...')\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "print('   Scaling complete!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Saving Preprocessed Data ===\n",
                        "\n",
                        "Preprocessed training data saved to: ../data/breast_cancer_preprocessed.csv\n",
                        "Shape: (455, 31)\n",
                        "\n",
                        "Preprocessing complete! Dataset is ready for model training."
                    ]
                }
            ],
            "source": [
                "# Save preprocessed data\n",
                "print('=== Saving Preprocessed Data ===')\n",
                "\n",
                "# Create preprocessed dataframe with scaled features\n",
                "X_train_df = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
                "X_train_df['target'] = y_train.values\n",
                "\n",
                "# Save to CSV\n",
                "preprocessed_path = '../data/breast_cancer_preprocessed.csv'\n",
                "X_train_df.to_csv(preprocessed_path, index=False)\n",
                "\n",
                "print(f'\\nPreprocessed training data saved to: {preprocessed_path}')\n",
                "print(f'Shape: {X_train_df.shape}')\n",
                "print('\\nPreprocessing complete! Dataset is ready for model training.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Baseline Model Training (Eksperimen)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Baseline Model: Random Forest ===\n",
                        "\n",
                        "Training Random Forest Classifier...\n",
                        "Training complete!\n",
                        "\n",
                        "=== Model Evaluation ===\n",
                        "Accuracy: 0.9649\n",
                        "\n",
                        "Classification Report:\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.98      0.93      0.95        42\n",
                        "           1       0.96      0.99      0.97        72\n",
                        "\n",
                        "    accuracy                           0.96       114\n",
                        "   macro avg       0.97      0.96      0.96       114\n",
                        "weighted avg       0.97      0.96      0.96       114"
                    ]
                }
            ],
            "source": [
                "print('=== Baseline Model: Random Forest ===')\n",
                "\n",
                "# Train model\n",
                "print('\\nTraining Random Forest Classifier...')\n",
                "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "rf_model.fit(X_train_scaled, y_train)\n",
                "print('Training complete!')\n",
                "\n",
                "# Predictions\n",
                "y_pred = rf_model.predict(X_test_scaled)\n",
                "\n",
                "# Evaluation\n",
                "print('\\n=== Model Evaluation ===')\n",
                "print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n",
                "print('\\nClassification Report:')\n",
                "print(classification_report(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "",
                        "text/plain": [
                            "<Figure size 800x600>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Confusion Matrix\n",
                "plt.figure(figsize=(8, 6))\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
                "            xticklabels=['Malignant', 'Benign'],\n",
                "            yticklabels=['Malignant', 'Benign'])\n",
                "plt.title('Confusion Matrix - Random Forest Baseline')\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('Actual')\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/baseline_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "",
                        "text/plain": [
                            "<Figure size 1000x600>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Top 10 Most Important Features:\n",
                        "1. worst concave points: 0.1456\n",
                        "2. worst perimeter: 0.1321\n",
                        "3. mean concave points: 0.1189\n",
                        "4. worst radius: 0.1087\n",
                        "5. mean perimeter: 0.0654\n",
                        "6. worst area: 0.0632\n",
                        "7. mean radius: 0.0598\n",
                        "8. mean concavity: 0.0543\n",
                        "9. mean area: 0.0487\n",
                        "10. worst concavity: 0.0421"
                    ]
                }
            ],
            "source": [
                "# Feature Importance\n",
                "feature_importance = pd.DataFrame({\n",
                "    'feature': X.columns,\n",
                "    'importance': rf_model.feature_importances_\n",
                "}).sort_values('importance', ascending=False)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "top_features = feature_importance.head(10)\n",
                "plt.barh(range(len(top_features)), top_features['importance'].values, color='#4ecdc4')\n",
                "plt.yticks(range(len(top_features)), top_features['feature'].values)\n",
                "plt.xlabel('Importance')\n",
                "plt.title('Top 10 Feature Importance')\n",
                "plt.gca().invert_yaxis()\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/feature_importance.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print('\\nTop 10 Most Important Features:')\n",
                "for i, row in top_features.iterrows():\n",
                "    idx = list(top_features.index).index(i) + 1\n",
                "    print(f\"{idx}. {row['feature']}: {row['importance']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Kesimpulan\n",
                "\n",
                "### Hasil Eksperimen:\n",
                "1. **Dataset**: Breast Cancer Wisconsin dengan 569 sampel dan 30 fitur\n",
                "2. **Preprocessing**: \n",
                "   - Tidak ada missing values\n",
                "   - Feature scaling dengan StandardScaler\n",
                "   - Train-test split 80:20 dengan stratified sampling\n",
                "3. **Baseline Model**: Random Forest dengan 100 estimators\n",
                "4. **Hasil**: Akurasi ~96.5% menunjukkan model baseline yang baik\n",
                "\n",
                "### Output:\n",
                "- `breast_cancer_preprocessed.csv`: Dataset hasil preprocessing yang siap untuk training model\n",
                "- Visualisasi EDA dan evaluasi model\n",
                "\n",
                "Dataset preprocessed akan digunakan pada tahap selanjutnya untuk training model dengan MLflow."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}